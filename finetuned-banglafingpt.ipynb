{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9402127,"sourceType":"datasetVersion","datasetId":5707596},{"sourceId":9815562,"sourceType":"datasetVersion","datasetId":6017898},{"sourceId":9853060,"sourceType":"datasetVersion","datasetId":6046157}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"_uuid":"9404d327-28a3-41b2-a00e-ff57ead1060b","_cell_guid":"2c8f0657-58db-473d-8a05-5dfa95e2b8c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:30:54.898944Z","iopub.execute_input":"2024-11-10T09:30:54.899336Z","iopub.status.idle":"2024-11-10T09:32:47.270490Z","shell.execute_reply.started":"2024-11-10T09:30:54.899294Z","shell.execute_reply":"2024-11-10T09:32:47.269176Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# !transformers-cli cache clear\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:32:47.272906Z","iopub.execute_input":"2024-11-10T09:32:47.273691Z","iopub.status.idle":"2024-11-10T09:32:47.277946Z","shell.execute_reply.started":"2024-11-10T09:32:47.273643Z","shell.execute_reply":"2024-11-10T09:32:47.277059Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"_uuid":"d60c3185-9415-4476-84f9-911c88f1121c","_cell_guid":"c2e51ca4-3082-4d7a-b1e2-4398975fcfa5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:32:47.279407Z","iopub.execute_input":"2024-11-10T09:32:47.279945Z","iopub.status.idle":"2024-11-10T09:33:06.812233Z","shell.execute_reply.started":"2024-11-10T09:32:47.279903Z","shell.execute_reply":"2024-11-10T09:33:06.811271Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"read_token='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'\nwrite_token='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'","metadata":{"_uuid":"59b7d2d9-af36-4aa4-afc3-53cef55d7cdf","_cell_guid":"a1bc1d6f-6ce8-4f59-814c-202cf43c3b87","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:06.814272Z","iopub.execute_input":"2024-11-10T09:33:06.814870Z","iopub.status.idle":"2024-11-10T09:33:06.818891Z","shell.execute_reply.started":"2024-11-10T09:33:06.814835Z","shell.execute_reply":"2024-11-10T09:33:06.818044Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\n# hf_token = user_secrets.get_secret(\"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\")\nlogin(token = write_token)","metadata":{"_uuid":"3563284c-3639-4d6b-b1e1-274e58da3671","_cell_guid":"849a5862-008d-4f03-8f6f-4b172484c32c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:06.820021Z","iopub.execute_input":"2024-11-10T09:33:06.820303Z","iopub.status.idle":"2024-11-10T09:33:06.973739Z","shell.execute_reply.started":"2024-11-10T09:33:06.820267Z","shell.execute_reply":"2024-11-10T09:33:06.972764Z"},"trusted":true},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!!wandb login","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:33:06.974937Z","iopub.execute_input":"2024-11-10T09:33:06.975251Z","iopub.status.idle":"2024-11-10T09:33:08.830259Z","shell.execute_reply.started":"2024-11-10T09:33:06.975218Z","shell.execute_reply":"2024-11-10T09:33:08.829301Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['wandb: ERROR Find detailed error logs at: /tmp/debug-cli.root.log',\n 'Error: api_key not configured (no-tty). call wandb login [your_api_key]']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#wb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key='fe579a1e3641448ce3a855814affb7dcb229a7f0')\nrun = wandb.init(\n    project='Fine-tune Llama 3 8B on Finance Dataset', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"_uuid":"ca0ccefd-9d67-4a26-a773-18f5daa8df66","_cell_guid":"72a84b01-5f9c-46fc-ab9a-5299b7af6c46","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:08.831414Z","iopub.execute_input":"2024-11-10T09:33:08.831758Z","iopub.status.idle":"2024-11-10T09:33:11.867766Z","shell.execute_reply.started":"2024-11-10T09:33:08.831725Z","shell.execute_reply":"2024-11-10T09:33:11.866793Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzafor4558\u001b[0m (\u001b[33mzafor4558-east-west-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241110_093310-hcmhnrpm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset/runs/hcmhnrpm' target=\"_blank\">neat-jazz-19</a></strong> to <a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset' target=\"_blank\">https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset/runs/hcmhnrpm' target=\"_blank\">https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset/runs/hcmhnrpm</a>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# base_model = \"meta-llama/Meta-Llama-3-8B\"\nbase_model='BanglaLLM/BanglaLLama-3.2-3b-bangla-alpaca-orca-instruct-v0.0.1'\ndataset_name = \"/kaggle/input/banglafin/Bangla_FinGpt.xlsx\"\nnew_model = \"BanglaLLM/BanglaLLama-3.2-3b-bangla-finance_fintuned-v0.0.1\"","metadata":{"_uuid":"b4a95e91-354f-416f-9f56-2d84d0e79ead","_cell_guid":"d6dcae0c-a5e0-4d91-8259-2f44cc8fb70c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:11.868968Z","iopub.execute_input":"2024-11-10T09:33:11.869266Z","iopub.status.idle":"2024-11-10T09:33:11.874264Z","shell.execute_reply.started":"2024-11-10T09:33:11.869233Z","shell.execute_reply":"2024-11-10T09:33:11.873410Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Set torch dtype and attention implementation\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"","metadata":{"_uuid":"f99213d6-da8a-464b-abae-f7fb93a240e1","_cell_guid":"ae79eb3a-b321-4009-ab17-aa43a9cb54ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:11.875491Z","iopub.execute_input":"2024-11-10T09:33:11.875805Z","iopub.status.idle":"2024-11-10T09:33:11.963027Z","shell.execute_reply.started":"2024-11-10T09:33:11.875775Z","shell.execute_reply":"2024-11-10T09:33:11.962091Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\n\n# Define your model name and attention implementation\nbase_model = \"BanglaLLM/BanglaLLama-3.2-3b-bangla-alpaca-orca-instruct-v0.0.1\"  # Replace with the actual model name\nattn_implementation = \"eager\"  # Change to \"eager\", \"flash_attention_2\", or \"sdpa\" as needed\n\n# QLoRA config with correct dtype\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,  # Use torch.float16 as the compute dtype\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model with quantization\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True, legacy=False)\n","metadata":{"_uuid":"5dc6c232-7a55-4c26-b955-1eed1fe7cfc0","_cell_guid":"6ef8d622-8283-413c-8525-9c4994ad306d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:33:11.966360Z","iopub.execute_input":"2024-11-10T09:33:11.966680Z","iopub.status.idle":"2024-11-10T09:36:13.727285Z","shell.execute_reply.started":"2024-11-10T09:33:11.966646Z","shell.execute_reply":"2024-11-10T09:36:13.726273Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/917 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37a293958c4a4d3987b9c4f7b9546681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"277fdcec15a84887b3679a62f2d66bff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33f1b6c78d294b08924f0883920dd834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd5869abb9f4420911a8754ddc7aa82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1314907b785f4ed2b0b68255b09549ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0160ccdc964b31a453b5bf5806e0bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/180 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10733d4331eb4cf0a67f21fa8e85b251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b04a601ba0d47a5959d1fa8f14ae121"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ca8d1c90c1b471f867cfb76f19001f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbc6a5819d449e7ad224c23e8fa623b"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=32,# which means parameter reduce to 7M\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)","metadata":{"_uuid":"148362b4-a001-4cb9-9256-4a9acd6aeefd","_cell_guid":"99a48b87-9236-461a-a19f-c1e429b0f7e0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:36:13.728532Z","iopub.execute_input":"2024-11-10T09:36:13.728874Z","iopub.status.idle":"2024-11-10T09:36:21.295144Z","shell.execute_reply.started":"2024-11-10T09:36:13.728840Z","shell.execute_reply":"2024-11-10T09:36:21.294155Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"\n# Test the base model","metadata":{}},{"cell_type":"code","source":"# Prepare input prompt\ninput_text = \"Tell me about Bangladesh.\"\n\n# Encode the input text using the tokenizer\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Move input_ids to the same device as the model (CUDA)\ninputs = {key: value.to(model.device) for key, value in inputs.items()}\n\n# Ensure that the model is in evaluation mode\nmodel.eval()\n\n# Generate the model's response with beam search\nwith torch.no_grad():\n    outputs = model.generate(\n        inputs[\"input_ids\"], \n        attention_mask=inputs.get(\"attention_mask\", None),  # Pass attention_mask explicitly\n        max_length=100,      # Increase max length for longer response\n        num_return_sequences=1, \n        num_beams=5,         # Use beam search with 5 beams\n        no_repeat_ngram_size=2,  # Prevent repeated n-grams\n        pad_token_id=tokenizer.pad_token_id,  # Ensure pad_token_id is set\n        eos_token_id=tokenizer.eos_token_id   # Set EOS token for ending\n    )\n\n# Decode the output tokens into a readable string\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Response:\", response)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:36:21.296485Z","iopub.execute_input":"2024-11-10T09:36:21.296852Z","iopub.status.idle":"2024-11-10T09:36:37.315126Z","shell.execute_reply.started":"2024-11-10T09:36:21.296816Z","shell.execute_reply":"2024-11-10T09:36:37.314153Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Response: Tell me about Bangladesh. আমাকে বাংলাদেশের ইতিহাস এবং প্রধান-sm্যক্তি সহ কিছু মোটিফ দিন।\nপার্ট ১: Bangladesh নিউজালেন\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Prepare input prompt\ninput_text = \"Do you know about Bangladesh?\"\n\n# Encode the input text using the tokenizer\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Move input_ids to the same device as the model (CUDA)\ninputs = {key: value.to(model.device) for key, value in inputs.items()}\n\n# Ensure that the model is in evaluation mode\nmodel.eval()\n\n# Generate the model's response with beam search\nwith torch.no_grad():\n    outputs = model.generate(\n        inputs[\"input_ids\"], \n        attention_mask=inputs.get(\"attention_mask\", None),  # Pass attention_mask explicitly\n        max_length=100,     # Increase max length for longer response\n        num_return_sequences=1, \n        num_beams=5,        # Use beam search with 5 beams\n        no_repeat_ngram_size=2,  # Prevent repeated n-grams\n        pad_token_id=tokenizer.eos_token_id  # Set pad_token explicitly\n    )\n\n# Decode the output tokens into a readable string\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Response:\", response)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:36:37.316237Z","iopub.execute_input":"2024-11-10T09:36:37.316560Z","iopub.status.idle":"2024-11-10T09:36:52.128933Z","shell.execute_reply.started":"2024-11-10T09:36:37.316518Z","shell.execute_reply":"2024-11-10T09:36:52.127989Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Response: Do you know about Bangladesh? �(বাংলাদেশ সম্পর্কে আপনার জ্ঞান কতক্ষণই ভালো তা নিয়ের প্রস্তাবিত মাসিক ইউটিলিট\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# Load your dataset from Excel\ndf = pd.read_excel(\"/kaggle/input/banglafin/Bangla_FinGpt.xlsx\")\n\n# Convert the pandas DataFrame to a Hugging Face Dataset\ndataset = Dataset.from_pandas(df)","metadata":{"_uuid":"91e792c3-b9c0-4039-9b96-d46e10ceb511","_cell_guid":"9e923d29-9efb-425a-8f08-1cfc8749ae5b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:36:52.130171Z","iopub.execute_input":"2024-11-10T09:36:52.130484Z","iopub.status.idle":"2024-11-10T09:36:55.691963Z","shell.execute_reply.started":"2024-11-10T09:36:52.130449Z","shell.execute_reply":"2024-11-10T09:36:55.690965Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Importing the dataset\n# dataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=65) # Only use 1000 samples for quick demo\n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"context\", \"content\": row[\"Context\"]}, {\"role\": \"question\", \"content\": row[\"Question\"]},\n               {\"role\": \"assistant\", \"content\": row[\"Answer\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc= 4,\n)\n\ndataset","metadata":{"_uuid":"2b26fc6f-43d3-40ae-83de-c8a625cb6291","_cell_guid":"c9a6fbce-9608-41d7-be71-dd6a19a20a67","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:36:55.693140Z","iopub.execute_input":"2024-11-10T09:36:55.693797Z","iopub.status.idle":"2024-11-10T09:37:02.377377Z","shell.execute_reply.started":"2024-11-10T09:36:55.693761Z","shell.execute_reply":"2024-11-10T09:37:02.376308Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/10412 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92b871261fba47eda695d46ecdbcef4b"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['QuestionID', 'Type', 'Topic', 'Context', 'Question', 'Answer', 'text'],\n    num_rows: 10412\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"dataset['text'][3]","metadata":{"_uuid":"cde0b15a-bc5f-4d16-868d-ed7dee0f2b29","_cell_guid":"db412448-3596-4ad0-a7c0-2f699425799f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:37:02.379135Z","iopub.execute_input":"2024-11-10T09:37:02.379552Z","iopub.status.idle":"2024-11-10T09:37:02.547923Z","shell.execute_reply.started":"2024-11-10T09:37:02.379501Z","shell.execute_reply":"2024-11-10T09:37:02.546824Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"<|im_start|>context\\n4% নির্ধারিত ব্যবসায়ের আয়ের প্রথম 10 লক্ষ এবং পরবর্তী চিত্রটিতে 2% গ্রহণযোগ্য হবে। আরএস 7: উত্স ((20/80)*8,00,000) লভ্যাংশ গ্রহণের লভ্যাংশ প্রাপ্তি আয় নোট 8: উৎসে 4,80,000 ছাড় প্রাপ্ত ব্যাংকের সুদ ((20/80)*48,00,000) 1,20,000 লভ্যাংশ আয় নোট 9: ভাড়া থেকে আয় (খ) বার্ষিক ভাড়া (গ) বর্জন: অনুমোদিত ব্যয় 30% ভাড়া মূল্য 12,00,000 করযোগ্য ভাড়া আয় 28,00,000 সিকিউরিটি ডিপোজিট [এটি মোট করযোগ্য আয়ের অন্তর্ভুক্ত হবে না কারণ সুরক্ষা আমানত হ'ল করদাতার দায়বদ্ধতা। এছাড়াও বাণিজ্যিক উদ্দেশ্যে ব্যবহৃত বাড়ির সম্পত্তিতে ব্যয়ের 30% ব্যয় করদাতার ধারা 38 (ডি) অনুযায়ী অনুমোদিত হবে। দ্রষ্টব্য 10: ধারা 163 (2) এর অধীনে ব্যবসায়িক আয়ের ভাগ। সংস্থাগুলি ব্যতীত খুচরা ব্যবসায়ীদের সরবরাহের 25,00,00,000 21% কোম্পানির বিক্রয় অনুপাত সরবরাহ নোট 11: সর্বনিম্ন ট্যাক্স টার্নওভার (1) 95.00,00,000 1,20,00,00,000 79% 1,20,00,00,000 সম্পদ হ'ল বিক্রয়যোগ্য 250,000 ব্যবসায়িক আয় থেকে ভাড়া মূলধন আয় থেকে আর্থিক সম্পদ থেকে অন্যান্য উত্স থেকে আয় থেকে আয় থেকে আয়ের পরিমাণ অন্যান্য প্রাপ্তি (2) মোট মোট প্রাপ্তি (1)+(2) স্থূল প্রাপ্তিগুলির উপর ন্যূনতম কর নির্ণয়ের উপর ন্যূনতম কর নির্ণয় 163 অনুযায়ী ব্যবসায়িক আয়ের উপর ন্যূনতম কর ( 5)। বিভাগ 163 (5) এর অধীনে সম্পদ বিক্রয় থেকে উদ্ভূত ব্যবসায়িক আয়। ধারা 163 (5) অনুযায়ী ভাড়া আয়ের উপর সর্বনিম্ন কর। ধারা 163 (5) অনুযায়ী মূলধন লাভের উপর ন্যূনতম কর। ধারা 163 (5) অনুযায়ী আর্থিক সম্পদ (সুদ) থেকে আয়ের ন্যূনতম কর। ধারা 163 (5) অনুযায়ী আর্থিক সম্পদ (লভ্যাংশ) থেকে আয়ের উপর ন্যূনতম কর। ধারা 163 (5) অনুযায়ী অন্যান্য আয়ের উপর ন্যূনতম কর। 58. আয়কর বিজ্ঞপ্তি 2023-2024 28,00,000 180,000 16,00,000 51.30,000 1.20.51.30,000 মান রেট 1,20,00,00,000 0.60% ডু 72,00,000 250,000 0.60% 1.5,00,000 0.60% 16,800 1, 80,000 0.60% 1.080 6,00,000 0.60% 3.600 10,00,000 0.60% 6,000 3,00,000 1,20,51,30,000 0.60% 1,800 72,30,30,780<|im_end|>\\n<|im_start|>question\\nধারা 163 (5) অনুযায়ী ব্যবসায়িক আয়ের উপর ন্যূনতম কর কত?<|im_end|>\\n<|im_start|>assistant\\nধারা 163 (5) অনুযায়ী ব্যবসায়িক আয়ের উপর সর্বনিম্ন কর প্রদত্ত সূত্রের ভিত্তিতে গণনা করা হয়।<|im_end|>\\n\""},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from datasets import DatasetDict\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T09:37:02.549210Z","iopub.execute_input":"2024-11-10T09:37:02.549534Z","iopub.status.idle":"2024-11-10T09:37:02.554766Z","shell.execute_reply.started":"2024-11-10T09:37:02.549495Z","shell.execute_reply":"2024-11-10T09:37:02.553766Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# # Split the training data within the DatasetDict\n# train_test_split = dataset['train'].train_test_split(test_size=0.1)\n\n# # Reconstruct the DatasetDict with the new splits\n# dataset = DatasetDict({\n#     'train': train_test_split['train'],\n#     'validation': train_test_split['test'],\n#     'test': dataset['test']  # Keep the existing test split if it exists\n# })\n\nfrom datasets import DatasetDict\n\n# Split the entire dataset into train, validation, and test sets\ndataset = dataset.train_test_split(test_size=0.1)  # First split: 90% train, 10% test\ntrain_val_split = dataset['train'].train_test_split(test_size=0.1)  # Second split: 10% validation of remaining 90%\n\n# Reorganize the splits into a DatasetDict\ndataset = DatasetDict({\n    'train': train_val_split['train'],\n    'validation': train_val_split['test'],\n    'test': dataset['test']\n})\n","metadata":{"_uuid":"0275db02-5357-438e-ae8f-006d4608b9a9","_cell_guid":"2c5814fd-790b-4098-8dcc-ef21d7803560","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:37:02.556024Z","iopub.execute_input":"2024-11-10T09:37:02.556769Z","iopub.status.idle":"2024-11-10T09:37:02.590155Z","shell.execute_reply.started":"2024-11-10T09:37:02.556722Z","shell.execute_reply":"2024-11-10T09:37:02.589279Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Hyperparameters\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,#5\n    evaluation_strategy=\"steps\",\n    eval_steps=250,\n    max_steps=5200,#5400\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=True,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n)","metadata":{"_uuid":"53a16608-6b12-4a01-aaf7-26cd243b8372","_cell_guid":"14189cb9-37e6-4349-8e3f-314f810fb6cc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:37:02.591251Z","iopub.execute_input":"2024-11-10T09:37:02.591531Z","iopub.status.idle":"2024-11-10T09:37:02.631345Z","shell.execute_reply.started":"2024-11-10T09:37:02.591495Z","shell.execute_reply":"2024-11-10T09:37:02.630435Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length= 512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"_uuid":"f37586ab-446c-466d-8e27-0171ad362820","_cell_guid":"8342c6c3-8ac5-45e1-8d3b-ca0182415983","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:37:02.632855Z","iopub.execute_input":"2024-11-10T09:37:02.633447Z","iopub.status.idle":"2024-11-10T09:38:00.929982Z","shell.execute_reply.started":"2024-11-10T09:37:02.633413Z","shell.execute_reply":"2024-11-10T09:38:00.929249Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8433 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6284fecd3d9479898c70fad3a712429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1042 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629a8235355c4a54ba57c417c4f3bb40"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"d09dfc13-0974-4f29-bf2e-dc894fc64e51","_cell_guid":"1615f47d-d8d0-4b69-b194-e9ca4341a691","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T09:38:00.931147Z","iopub.execute_input":"2024-11-10T09:38:00.931521Z","iopub.status.idle":"2024-11-10T14:32:26.301511Z","shell.execute_reply.started":"2024-11-10T09:38:00.931477Z","shell.execute_reply":"2024-11-10T14:32:26.299615Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5001' max='5200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5001/5200 4:49:12 < 11:30, 0.29 it/s, Epoch 2.37/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>1.683200</td>\n      <td>1.171090</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.374300</td>\n      <td>0.824341</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.129700</td>\n      <td>0.551133</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.989900</td>\n      <td>0.377911</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.864200</td>\n      <td>0.251079</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.527600</td>\n      <td>0.179332</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.356400</td>\n      <td>0.127868</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.318200</td>\n      <td>0.096870</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.087500</td>\n      <td>0.081882</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.048300</td>\n      <td>0.072331</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.050900</td>\n      <td>0.067751</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.038000</td>\n      <td>0.063169</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.039300</td>\n      <td>0.058178</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.037300</td>\n      <td>0.054659</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>0.039600</td>\n      <td>0.052014</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.037300</td>\n      <td>0.050631</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>0.037300</td>\n      <td>0.049951</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.038600</td>\n      <td>0.049542</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>0.037700</td>\n      <td>0.049123</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.037900</td>\n      <td>0.048923</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3007\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3097\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3095\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3096\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 3097\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   3101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3727\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3729\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3834\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3832\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   3833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3835\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   3836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3839\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:369\u001b[0m, in \u001b[0;36mPeftModel.save_pretrained\u001b[0;34m(self, save_directory, safe_serialization, selected_adapters, save_embedding_layers, is_main_process, convert_pissa_to_lora, path_initial_model_for_weight_conversion, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m         peft_config\u001b[38;5;241m.\u001b[39msave_pretrained(path_initial_model_for_weight_conversion)\n\u001b[1;32m    366\u001b[0m         output_state_dict \u001b[38;5;241m=\u001b[39m save_mutated_as_lora(\n\u001b[1;32m    367\u001b[0m             peft_config, path_initial_model_for_weight_conversion, output_state_dict, kwargs\n\u001b[1;32m    368\u001b[0m         )\n\u001b[0;32m--> 369\u001b[0m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAFETENSORS_WEIGHTS_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_main_process:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path_initial_model_for_weight_conversion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/safetensors/torch.py:286\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    256\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    257\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    258\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m ):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[43mserialize_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"],"ename":"SafetensorError","evalue":"Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T14:41:05.292845Z","iopub.execute_input":"2024-11-10T14:41:05.293247Z","iopub.status.idle":"2024-11-10T14:41:08.368970Z","shell.execute_reply.started":"2024-11-10T14:41:05.293207Z","shell.execute_reply":"2024-11-10T14:41:08.367515Z"},"trusted":true},"outputs":[{"name":"stderr","text":"--- Logging error ---\n/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2374: UserWarning: Run (hcmhnrpm) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n  lambda data: self._console_raw_callback(\"stderr\", data),\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2414, in _atexit_cleanup\n    logger.info(f\"got exitcode: {exit_code}\")\nMessage: 'got exitcode: 0'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2426, in _atexit_cleanup\n    self._on_finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2664, in _on_finish\n    self._console_stop()  # TODO: there's a race here with jupyter console logging\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2463, in _console_stop\n    self._restore()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2396, in _restore\n    logger.info(\"restore\")\nMessage: 'restore'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2426, in _atexit_cleanup\n    self._on_finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2664, in _on_finish\n    self._console_stop()  # TODO: there's a race here with jupyter console logging\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2463, in _console_stop\n    self._restore()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2402, in _restore\n    logger.info(\"restore done\")\nMessage: 'restore done'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2439, in _atexit_cleanup\n    Run._footer(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3861, in _footer\n    Run._footer_history_summary_info(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3963, in _footer_history_summary_info\n    logger.info(\"rendering history\")\nMessage: 'rendering history'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2439, in _atexit_cleanup\n    Run._footer(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3861, in _footer\n    Run._footer_history_summary_info(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3995, in _footer_history_summary_info\n    logger.info(\"rendering summary\")\nMessage: 'rendering summary'\nArguments: ()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄█▃▇▅▃▇▅▇▆▇▅▄▃▄▂▁▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▇▂▄▅▂▄▁▂▂▄▅▇▅▇███▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▇▂▄▅▂▄▁▂▂▄▅▇▅▇███▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▄▅▅▅▅▆▅▆▆▆▆▇▇▇▄█▃▃▃▄▅▂▆▅▄▂▄▂▃▂▂▃▃▂▁▂▇▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▄▄▃▃▂▃▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.04892</td></tr><tr><td>eval/runtime</td><td>297.1255</td></tr><tr><td>eval/samples_per_second</td><td>3.507</td></tr><tr><td>eval/steps_per_second</td><td>3.507</td></tr><tr><td>train/epoch</td><td>2.37135</td></tr><tr><td>train/global_step</td><td>5000</td></tr><tr><td>train/grad_norm</td><td>0.06471</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0379</td></tr></table><br/></div></div>"},"metadata":{}},{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_31/2127913808.py\", line 1, in <module>\n    wandb.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 4157, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 451, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 393, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2139, in finish\n    return self._finish(exit_code, quiet)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2173, in _finish\n    self._atexit_cleanup(exit_code=exit_code)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 2439, in _atexit_cleanup\n    Run._footer(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3869, in _footer\n    Run._footer_sync_info(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 3922, in _footer_sync_info\n    logger.info(\"logging synced files\")\nMessage: 'logging synced files'\nArguments: ()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">neat-jazz-19</strong> at: <a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset/runs/hcmhnrpm' target=\"_blank\">https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset/runs/hcmhnrpm</a><br/> View project at: <a href='https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset' target=\"_blank\">https://wandb.ai/zafor4558-east-west-university/Fine-tune%20Llama%203%208B%20on%20Finance%20Dataset</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241110_093310-hcmhnrpm/logs</code>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/logging/__init__.py:1180\u001b[0m, in \u001b[0;36mFileHandler.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/logging/__init__.py:1084\u001b[0m, in \u001b[0;36mStreamHandler.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1084\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:4157\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   4147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mark a run as finished, and finish uploading all data.\u001b[39;00m\n\u001b[1;32m   4148\u001b[0m \n\u001b[1;32m   4149\u001b[0m \u001b[38;5;124;03mThis is used when creating multiple runs in the same process.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;124;03m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun:\n\u001b[0;32m-> 4157\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:451\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:393\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2139\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_noop\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_attach\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\u001b[38;5;28mself\u001b[39m, exit_code: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, quiet: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mark a run as finished, and finish uploading all data.\u001b[39;00m\n\u001b[1;32m   2131\u001b[0m \n\u001b[1;32m   2132\u001b[0m \u001b[38;5;124;03m    This is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;124;03m        quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   2138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2179\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks:\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m TeardownStage\u001b[38;5;241m.\u001b[39mLATE:\n\u001b[0;32m-> 2179\u001b[0m         \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;66;03m# Inform the service that we're done sending messages for this run.\u001b[39;00m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;66;03m# TODO: Why not do this in _atexit_cleanup()?\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:407\u001b[0m, in \u001b[0;36m_WandbInit._enable_logging.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# TODO: make me configurable\u001b[39;00m\n\u001b[1;32m    404\u001b[0m logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    406\u001b[0m     TeardownHook(\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, logger\u001b[38;5;241m.\u001b[39mremoveHandler(handler)),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    408\u001b[0m         TeardownStage\u001b[38;5;241m.\u001b[39mLATE,\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/logging/__init__.py:1185\u001b[0m, in \u001b[0;36mFileHandler.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1185\u001b[0m                 \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;66;03m# Issue #19523: call unconditionally to\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;66;03m# prevent a handler leak when delay is set\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;66;03m# Also see Issue #42378: we also rely on\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;66;03m# self._closed being set to True there\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     StreamHandler\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"# Instruction set","metadata":{}},{"cell_type":"code","source":"# 1. \n#   question: কীভাবে ইলেকট্রনিক রেকর্ড সংরক্ষণ করা হয়?\n#   type: customs\n\n# 2. \n#   question: কীভাবে সরকার প্রস্তুতকৃত পণ্যের আনয়ন বা নেওয়া নিয়ন্ত্রণ করতে পারে?\n#   type: customs\n\n# 3. \n#   question: কোনো যানবাহনে কি কি শ্রেণির অথবা বর্ণনার নৌযানের চলাচল নিষিদ্ধ?\n#   type: customs\n\n# 4. \n#   question: ওয়্যারহাউসে পণ্য গ্রহণের ক্ষমতা সাধারিত কোন পদ্ধতিতে হবে?\n#   type: customs\n\n# 5. \n#   question: নির্দিষ্ট অধ্যাদেশ অনুযায়ী অপ্রকাশিত সম্পত্তি এবং নগদ সংক্রান্ত বিশেষ কর চিকিত্সা কি?\n#   type: finance\n\n# 6. \n#   question: বিনিয়োগের হার (করের হার) সম্পর্কিত ধারা 52-এ সংশোধিত বিধান কী?\n#   type: finance\n\n# 7. \n#   question: ফ্লাইং ক্লাব অব বাংলাদেশ, সংশ্লিষ্ট সরকারি বিভাগ এবং ভ্যাট-নিবন্ধিত নির্মাতারা কাঁচামাল হিসেবে কী কী শ্রেণির পণ্য আমদানি করছে?\n#   type: finance\n\n# 8. \n#   question: প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্র কোন বিভাগে অন্তর্ভুক্ত?\n#   type: finance\n\n# 9.\n#   question: আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং কর আরোপের ক্ষেত্রে কী পরিবর্তন হয়েছে?\n#   type: tax\n\n# 10. \n#   question: অতিরিক্ত কমিশনার অফ ট্যাক্সেস (আপীল)\" শব্দটি কাকে বোঝায় এবং আইনে এটি কোথায় উল্লেখ করা হয়েছে?\n#   type: tax\n\n# 11. \n#   question: কীভাবে কল্প অর্থ আয়ের উপর কর প্রদান করতে হয়?\n#   type: tax\n\n# 12. \n#   question: নগদ লভ্যাংশের চেয়ে বেশি স্টক লভ্যাংশের ক্ষেত্রে কী করের হার প্রযোজ্য?\n#   type: tax\n\n# 13.\n#   question: একজন নিবন্ধিত ব্যক্তি কীভাবে রিটার্ন শংসাপত্র জারি করার অনুমতিের জন্য আবেদন করেন?\n#   type: vat\n\n# 14. \n#   question: ডিফল্ট করদাতা নির্দিষ্ট সময়ের মধ্যে মেনে না নিলে ব্যবসায় প্রতিষ্ঠা বন্ধ এবং সিল করার পরে পরবর্তী পদক্ষেপটি কী?\n#   type: vat\n\n# 15.\n#   question: ভ্যাট গ্রাহকের দায়িত্ব কী?\n#   type: vat\n\n# 16. \n#   question: কমিশনার কীভাবে বিকল্প বিরোধ নিষ্পত্তিতে মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়ককে মনোনীত করেন?\n#   type: vat","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Answer manually","metadata":{}},{"cell_type":"code","source":"# Define the Question variable as a string\n#Question = \"What is electronic record storage?\"\n\nmessages = [{\"role\": \"system\", \"content\": \"Please provide a detailed answer\"},\n            {\"role\": \"user\", \"content\": \"  কীভাবে কল্প অর্থ আয়ের উপর কর প্রদান করতে হয়?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\n# Generate the response\noutputs = model.generate(**inputs, max_new_tokens=2000, num_return_sequences=1)\n\n# Decode the response\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-10T19:13:37.102662Z","iopub.execute_input":"2024-11-10T19:13:37.103549Z","iopub.status.idle":"2024-11-10T19:13:37.470827Z","shell.execute_reply.started":"2024-11-10T19:13:37.103504Z","shell.execute_reply":"2024-11-10T19:13:37.469308Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the Question variable as a string\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Question = \"What is electronic record storage?\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide a detailed answer\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      5\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  কীভাবে কল্প অর্থ আয়ের উপর কর প্রদান করতে হয়?\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m----> 7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generate the response\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# Using loop until i quit","metadata":{}},{"cell_type":"code","source":"# Define the main loop\nwhile True:\n    # Ask for the question in Bengali (or English, if desired)\n    user_question = input(\"Enter your question (or type 'quit' to exit): \")\n    \n    # Exit if the user types 'quit'\n    if user_question.lower() == 'quit':\n        print(\"Exiting the Q&A session.\")\n        break\n    \n    # Set up the messages with system and user question\n    messages = [{\"role\": \"system\", \"content\": \"Please provide a detailed answer\"},\n                {\"role\": \"user\", \"content\": user_question}]\n    \n    # Apply the chat template to format the messages\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    # Prepare the inputs for the model\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n    \n    # Generate the response\n    outputs = model.generate(**inputs, max_new_tokens=2000, num_return_sequences=1)\n    \n    # Decode the response\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    # Print the generated answer\n    print(\"Answer:\", text)\n","metadata":{"trusted":true},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং কর আরোপের ক্ষেত্রে কী পরিবর্তন হয়েছে?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nআয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং কর আরোপের ক্ষেত্রে কী পরিবর্তন হয়েছে?\nassistant\nআয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের ক্ষেত্রে কোনও পরিবর্তন নেই। এটি হ'য় না কারণ, বর্তমানে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের জন্য বিধি প্রয়োজন। এই বিধি সাধারণত বাজেটের সাথে পরিবর্তন করা হয়। তদনুভাবে পরিশোধিত নয় এমন ক্ষেত্রে বিধি প্রয়োজন। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি পরিবর্তন করা হয়েছে। এই সমস্ত বিধানগুলি বাজেটের সাথে সঙ্গতিপূর্ণ হবে। এক্ষেত্রে, যদি কোনও পরিবর্তন আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলির প্রয়োজন হয় তবে বিধানগুলি পরিবর্তন করা হবে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি সংযোজন করা হবে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি বিলুপ্ত করা হবে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি সংশোধন করা হবে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি সমস্ত পরিবর্তন সত্ত্বেও, এই সমস্ত বিধানগুলি বাজেটের সাথে সঙ্গতিপূর্ণ থাকবে। এই সমস্ত বিধানগুলি একটি বিধি নিয়ম অনুসারে সামঞ্জস্য করা হয়েছে, যা বর্তমানে প্রযোজ্য। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি বিধি নিয়ম অনুসারে সংযোজন করা হয়েছে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি বিলুপ্ত করা হয়েছে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর, ন্যূনতম কর, সারচার্জ এবং আয়কর আরোপের বিধানগুলি সংশোধন করা হয়েছে। এই ক্ষেত্রে, আয়কর, অগ্রিম আয়কর, উৎসে কর,\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  ওয়্যারহাউসে পণ্য গ্রহণের ক্ষমতা সাধারিত কোন পদ্ধতিতে হবে?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nওয়্যারহাউসে পণ্য গ্রহণের ক্ষমতা সাধারিত কোন পদ্ধতিতে হবে?\nassistant\nসাধারণ শর্তে, ভাল ব্যক্তির মধ্যে, কোন পদ্ধতিতে যদি একজন কর্মচারীর মাধ্যমে পণ্য গ্রহণের ক্ষমতা থাকে তবে এটি করা হবে। যদি কোনো পণ্য প্রস্তুতকারক পদ্ধতির অধীনে প্রস্তুত করা হয় তবে এটি প্রস্তুতকারক তার মাধ্যমে সাধারণত কোন কর্মচারীর মাধ্যমে পণ্য গ্রহণের জন্য জল-পানীয় শর্ত সাপেক্ষে করা হয়। তবে কোনো কর্মচারী যদি ভাল শর্তে পণ্য গ্রহণের জন্য দায়িত্বপ্রাপ্ত হয় তবে পণ্য গ্রহণের জন্য কোন পদ্ধতি সাধারণত করা হয়। একজন কর্মচারীর মাধ্যমে পণ্য গ্রহণের জন্য কোনো পদ্ধতি সাধারণত নিম্নলিখিত এই পদ্ধতি অনুসারে গ্রহণ করা হয়েছে, যথা:- (ক) কর্মচারী পণ্য গ্রহণের জন্য দায়িত্ব পাওয়ার সহিত সম্মত হয় তবে নির্দিষ্ট করে যে তিনি কোনো পদ্ধতিতে পণ্য গ্রহণ করবেন। উদাহরণস্বরূপ, \"কর্মচারী টঢঢাকা পণ্য গ্রহণের জন্য আমন্ত্রণ জানায়, বিল প্রদান করে এবং পণ্য গ্রহণের সময়ে স্বাভাবিক শর্ত পূরণ সাপেক্ষে পণ্য গ্রহণের অনুমতি প্রদান করে।\"; (খ) কর্মচারী পণ্য গ্রহণের জন্য অনুমতি প্রাপ্ত হলে কর্মচারী উপযুক্ত পদ্ধতিতে পণ্য গ্রহণ করবে। এই ক্ষেত্রে, কর্মচারী অনুমোদিত পদ্ধতিতে পণ্য গ্রহণের বিপরীতে কোনো অধ্যাদেশ বা আইনের অধীনে কোনো অপরাধ সংঘটিত হওয়ার বিষয়ে দায়বদ্ধ থাকবেন। একজন কর্মচারী যদি পণ্য গ্রহণের জন্য অনুমতি প্রাপ্ত হয় এবং উপযুক্ত পদ্ধতিতে পণ্য গ্রহণ করেন তবে কোনো অপরাধ সংঘটিত হওয়ার বিষয়ে তিনি দায়ী হবেন না। এই ক্ষেত্রে, যদি কোনো অধ্যাদেশ বা আইন কোনো কিছু উল্লেখ করে থাকে তবে কর্মচারী উক্ত অধ্যাদেশ বা আইনের অধীনে পণ্য গ্রহণের বিরুদ্ধে দায়বদ্ধ হবেন। এই জাতীয় পরিস্থিতিতে কতিপয় কর্মচারী পণ্য গ্রহণের অধিকারী কর্তৃপক্ষের নিকট কোনো অধ্যাদেশ বা আইনের অধীনে পণ্য গ্রহণের জন্য অনুমতি প্রদান করবেন এবং উপযুক্ত পদ্ধতিতে পণ্য গ্রহণ করবেন। এই জাতীয় পরিস্থিতিতে কোনো কর্মচারী যদি অনুমোদিত পদ্ধতিতে পণ্য গ্রহণের বিপরীতে কোনো অধ্যাদেশ বা আইনের অধীনে অপরাধ সংঘটিত হওয়ার দায়ে দায়ী হবেন। এই �\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  নির্দিষ্ট অধ্যাদেশ অনুযায়ী অপ্রকাশিত সম্পত্তি এবং নগদ সংক্রান্ত বিশেষ কর চিকিত্সা কি?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nনির্দিষ্ট অধ্যাদেশ অনুযায়ী অপ্রকাশিত সম্পত্তি এবং নগদ সংক্রান্ত বিশেষ কর চিকিত্সা কি?\nassistant\nঅপ্রকাশিত সম্পত্তি এবং অর্থের বিশেষ কর চিকিত্সা হ'ল অধ্যাদেশ দ্বারা নির্ধারিত সীমাবদ্ধতার মধ্যে সম্পত্তি এবং অর্থের নির্দিষ্ট ক্ষেত্রে প্রদেয় বিশেষ কর চিত্র। এটি এই জাতীয় সম্পত্তি এবং অর্থের বিক্রয়, প্রত্যর্পণ, উত্পাদন, বিক্রয়, স্থানান্তর ইত্যাদির সহিত জড়িত থাকতে পারে। কারণ, এই জাতীয় সম্পত্তি এবং অর্থ করদাতারা প্রদেয় করের একটি ছাড় উপযোগী করার জন্য বিধান দেওয়া হয়। কিছু ক্ষেত্রে, এই জাতীয় সম্পত্তি এবং অর্থের বিক্রয়, প্রত্যর্পণ, উত্পাদন, বিক্রয়, স্থানান্তর ইত্যাদির সহিত জড়িত থাকলে উপযোগী করার জন্য বিধান দেওয়া হয়। এই জাতীয় সম্পত্তি এবং অর্থের ক্ষেত্রে প্রযোজ্য বিশেষ কর চিত্রটি অধ্যাদেশ দ্বারা নির্ধারিত সীমাবদ্ধতার মধ্যে প্রদান করা হবে। এটি লক্ষ করা উচিত যে বিধিবদ্ধ কর্মকাণ্ডের জন্য প্রযোজ্য কর চিত্র একটি অপরিশোধিত অর্থ উত্পাদন বা উত্পাদনের সাথে সম্পর্কিত থাকতে পারে। উদাহরণস্বরূপ: কোনও সম্পত্তি বা অর্থপ্রদান অপ্রকাশিত রাখা যাকে করদাতা অবশ্যই নির্দিষ্ট অধ্যাদেশ অনুযায়ী ট্যাক্স ছাড় পাবেন। এছাড়া, কোনও করযোগ্য সম্পত্তি বা অর্থপ্রদানের ক্ষেত্রে কাজটি উপযোগী করার জন্য অধ্যাদেশ দ্বারা বিধ্বংবন সংযোজন করা যেতে পারে। এটি লক্ষ করা উচিত যে, এই জাতীয় সম্পত্তি এবং অর্থের ক্ষেত্রে প্রযোজ্য বিশেষ কর চিত্রটি অধ্যাদেশ দ্বারা নির্ধারিত সীমাবদ্ধতার মধ্যে প্রদান করা হবে। এটি লক্ষ করা উচিত যে, বিধিবদ্ধ কর্মকাণ্ডের জন্য প্রযোজ্য কর চিত্র একটি অপরিশোধিত অর্থ উত্পাদন বা উত্পাদনের সাথে সম্পর্কিত থাকতে পারে। উদাহরণস্বরূপ: কোনও সম্পত্তি বা অর্থপ্রদান অপ্রকাশিত রাখা যাকে করদাতা অবশ্যই নির্দিষ্ট অধ্যাদেশ অনুযায়ী ট্যাক্স ছাড় পাবেন। এছাড়া, কোনও করযোগ্য সম্পত্তি বা অর্থপ্রদানের ক্ষেত্রে কাজটি উপযোগী করার জন্য অধ্যাদেশ দ্বারা বিধ্বংবন সংযোজন করা যেতে পারে। এই জাতীয় সম্পত্তি এবং অর্থের ক্ষেত্রে প্রযোজ্য বিশেষ কর চিত্রটি অধ্যাদেশ দ্বারা নির্ধারিত সীমাবদ্ধতার মধ্যে প্রদান কর\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):   বিনিয়োগের হার (করের হার) সম্পর্কিত ধারা 52-এ সংশোধিত বিধান কী?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\n বিনিয়োগের হার (করের হার) সম্পর্কিত ধারা 52-এ সংশোধিত বিধান কী?\nassistant\nঅর্থ আইনের বিধান বই 2015 এর পরে বিনিয়োগ করের হার সম্পর্কিত ধারা 52 এ সংশোধন করা হয়েছে। বিধান বই 2015 এর ধারা 52 এর সংশোধনের পরে, করদাতাদের একটি নির্দিষ্ট আয়ের সুপার এবং নিম্নকরার জন্য একটি নির্দিষ্ট বিনিয়োগ করের হার থাকবে। এই ধারায় যে কোনও প্রকার বিনিয়োগ এবং যে কোনও প্রকার বিনিয়োগ সম্পর্কিত হার উল্লেখ করা হবে। কারণ, কোনও করদাতা এর আয়ের সুপার এবং নিম্নকরণের জন্য একটি প্রকার বিনিয়োগের জন্য হার নির্ধারণ করতে পারে, যা তার করের মোট হার নির্ধারণে অবদান রাখবে। এটি লক্ষণীয় যে একটি সম্পূর্ণ অর্থনার্থিক সম্প্রচারের সাথে সম্পর্কিত যে কোনও বিনিয়োগের প্রভাব একটি করদাতার আয়ের সুপার এবং নিম্নকরণের উপর সরাসরি প্রয়োগ করা হবে। এই ধারায় যে কোনও বিনিয়োগ এবং যে কোনও বিনিয়োগের ক্ষেত্রে একটি সুপার এবং নিম্নকরণের জন্য হার উল্লেখ করা হবে। এটি লক্ষণীয় যে একটি সম্পূর্ণ অর্থনার্থিক সম্প্রচারের সাথে সম্পর্কিত যে কোনও বিনিয়োগের প্রভাব একটি করদাতার আয়ের সুপার এবং নিম্নকরণের উপর সরাসরি প্রয়োগ করা হবে। এই ধারায় যে কোনও বিনিয়োগ এবং যে কোনও বিনিয়োগের ক্ষেত্রে একটি সুপার এবং নিম্নকরণের জন্য হার উল্লেখ করা হবে। এটি লক্ষণীয় যে একটি সম্পূর্ণ অর্থনার্থিক সম্প্রচারের সাথে সম্পর্কিত যে কোনও বিনিয়োগের প্রভাব একটি করদাতার আয়ের সুপার এবং নিম্নকরণের উপর সরাসরি প্রয়োগ করা হবে। এই ধারায় যে কোনও বিনিয়োগ এবং যে কোনও বিনিয়োগের ক্ষেত্রে একটি সুপার এবং নিম্নকরণের জন্য হার উল্লেখ করা হবে। এটি লক্ষণীয় যে একটি সম্পূর্ণ অর্থনার্থিক সম্প্রচারের সাথে সম্পর্কিত যে কোনও বিনিয়োগের প্রভাব একটি করদাতার আয়ের সুপার এবং নিম্নকরণের উপর সরাসরি প্রয়োগ করা হবে। এই ধারায় যে কোনও বিনিয়োগ এবং যে কোনও বিনিয়োগের ক্ষেত্রে একটি সুপার এবং নিম্নকরণের জন্য হার উল্লেখ করা হবে। এটি লক্ষণীয় যে একটি সম্পূর্ণ অর্থনার্থিক সম্প্রচারের সাথে সম্পর্কিত যে কোনও বিনিয়োগের প্রভাব এক�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  বিনিয়োগের হার (করের হার) সম্পর্কিত ধারা 52-এ সংশোধিত বিধান কী?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nবিনিয়োগের হার (করের হার) সম্পর্কিত ধারা 52-এ সংশোধিত বিধান কী?\nassistant\nঅবশ্যই, বিনিয়োগ হার (ট্যাক্স হার) এর জন্য বিধানগুলি সংশোধন করা হয়েছে। আগে, করদাতারা নির্দিষ্ট করহারে নির্দিষ্ট আয়ের বিপরীতে ন্যূনতম কর দাবি করতে পারতেন। এসএসএইচ. আইন, ২০২৩ এর মাধ্যমে, এখন করদাতারা নির্দিষ্ট করহারে নির্দিষ্ট আয়ের বিপরীতে ন্যূনতম কর দাবি করতে পারেন এবং উপযুক্ত কর হারে আয়ের উপর অতিরিক্ত কর দাবি করতে পারেন। এটি লক্ষ করা উচিত যে করদাতারা এখন আয়ের সাথে সম্পর্কিত সমস্ত আয়ের বিপরীতে কর দাবি করতে পারে, ন্যূনতম কর দাবি করতে পারে, অথবা উপযুক্ত কর হারে আয়ের উপর অতিরিক্ত কর দাবি করতে পারে। ধারা ৫২-এর সংশোধন নিয়মটি কর কর্তৃপক্ষের বিধানগুলির সাথে সম্মতি নিশ্চিত করতে এবং কর সংক্রান্ত সম্পর্কিত সমস্ত বিধানগুলির সাথে সম্মতি নিশ্চিত করতে অগ্রহণযোগ্য। এটি লক্ষ করা উচিত যে করদাতারা এখন আয়ের সাথে সম্পর্কিত সমস্ত আয়ের বিপরীতে কর দাবি করতে পারে, ন্যূনতম কর দাবি করতে পারে, অথবা উপযুক্ত কর হারে আয়ের উপর অতিরিক্ত কর দাবি করতে পারে। ধারা ৫২-এর সংশোধন নিয়মটি কর কর্তৃপক্ষের বিধানগুলির সাথে সম্মতি নিশ্চিত করতে এবং কর সংক্রান্ত সম্পর্কিত সমস্ত বিধানগুলির সাথে সম্মতি নিশ্চিত করতে অগ্রহণযোগ্য। এটি লক্ষ করা উচিত যে করদাতারা এখন আয়ের সাথে সম্পর্যত সমস্ত আয়ের বিপরীতে কর দাবি করতে পারে, ন্যূনতম কর দাবি করতে পারে, অথবা উপযুক্ত কর হারে আয়ের উপর অতিরিক্ত কর দাবি করতে পারে। ধারা ৫২-এর সংশোধন নিয়মটি কর কর্তৃপক্ষের বিধানগুলির সাথে সম্মতি নিশ্চিত করতে এবং কর সংক্রান্ত সম্পর্কিত সমস্ত বিধানগুলির সাথে সম্মতি নিশ্চিত করতে অগ্রহণযোগ্য। এটি লক্ষ করা উচিত যে করদাতারা এখন আয়ের সাথে সম্পর্যত সমস্ত আয়ের বিপরীতে কর দাবি করতে পারে, ন্যূনতম কর দাবি করতে পারে, অথবা উপযুক্ত কর হারে আয়ের উপর অতিরিক্ত কর দাবি করতে পারে। ধারা ৫২-এর সংশোধন নিয়মটি কর কর্তৃপক্ষের বিধানগুলির সাথে সম্মতি নিশ্চিত করতে এবং কর সংক্রান্ত সম্পর্কিত সমস্ত বিধানগুলির সাথে সম্মতি নিশ্চিত করতে �\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  ফ্লাইং ক্লাব অব বাংলাদেশ, সংশ্লিষ্ট সরকারি বিভাগ এবং ভ্যাট-নিবন্ধিত নির্মাতারা কাঁচামাল হিসেবে কী কী শ্রেণির পণ্য আমদানি করছে?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nফ্লাইং ক্লাব অব বাংলাদেশ, সংশ্লিষ্ট সরকারি বিভাগ এবং ভ্যাট-নিবন্ধিত নির্মাতারা কাঁচামাল হিসেবে কী কী শ্রেণির পণ্য আমদানি করছে?\nassistant\nবিকল্প কর্তৃপক্ষ যে কোনও শ্রেণির পণ্য আমদানির জন্য বিভিন্ন শ্রেণির ভ্যাট করতে পারে। যদি এই উপসংক্রান্তে সরকারের অধিকন্তু কোনও আইন বা আদেশ থাকে তবে এই ক্ষেত্রে শুধুমাত্র আদেশ থাকবে। যদি ভ্যাট কমিশনার যে কোনও শ্রেণির পণ্য আমদানির জন্য শুল্ক নির্ধারণ করতে পারেন, তবে এটি করবেন। শুল্ক আদায়ের ক্ষেত্রে, আমদানির উদ্দেশ্য সম্পর্কিত পণ্যের গুণাবলী, উপাদানগুলির পরিমাণ, উপকরণগুলির উৎস এবং বৈদেশিক মূল্য সম্পর্কিত অন্যান্য তথ্যগুলি মূল্যায়ন করার পরে, ভ্যাট কমিশনার উপযুক্ত শুল্ক হারে উপযুক্ত শুল্ক হারে আমদানির উদ্দেশ্যে কাঁচামাল শ্রেণির পণ্য আমদানির জন্য শুল্ক আদায় করবেন। এই ক্ষেত্রে, ভ্যাট কমিশনার যথাযথ কর্তৃপক্ষের অধীনে উপযুক্ত শুল্ক হারে ভ্যাট আরোপ করবেন। এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক্ষেত্রে, এই ক\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  quit\n"},{"name":"stdout","text":"Exiting the Q&A session.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Define the main loop\nwhile True:\n    # Ask for the question in Bengali (or English, if desired)\n    user_question = input(\"Enter your question (or type 'quit' to exit): \")\n    \n    # Exit if the user types 'quit'\n    if user_question.lower() == 'quit':\n        print(\"Exiting the Q&A session.\")\n        break\n    \n    # Set up the messages with system and user question\n    messages = [{\"role\": \"system\", \"content\": \"Please provide a detailed answer\"},\n                {\"role\": \"user\", \"content\": user_question}]\n    \n    # Apply the chat template to format the messages\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    # Prepare the inputs for the model\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n    \n    # Generate the response\n    outputs = model.generate(**inputs, max_new_tokens=2000, num_return_sequences=1)\n    \n    # Decode the response\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    # Print the generated answer\n    print(\"Answer:\", text)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T18:18:10.847859Z","iopub.execute_input":"2024-11-10T18:18:10.848276Z","iopub.status.idle":"2024-11-10T18:57:46.173006Z","shell.execute_reply.started":"2024-11-10T18:18:10.848240Z","shell.execute_reply":"2024-11-10T18:57:46.172010Z"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্র কোন বিভাগে অন্তর্ভুক্ত?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nপ্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্র কোন বিভাগে অন্তর্ভুক্ত?\nassistant\nপ্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রগুলি প্রযুক্তিগত নকল বা অনুকরণের জন্য বিভিন্ন প্রক্রিয়াকরণ এবং প্রযুক্তির ব্যবহার নিয়ে জড়িত। এই জাতীয় পণ্যগুলি সাধারণত প্লাস্টিকের উপযোগিতা ব্যবহার করে তৈরি করা হয়। সুতরাং, এই জাতীয় পণ্যগুলি প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রের বিভাগে শ্রেণীবদ্ধ করা হবে। এটি লক্ষ করা উচিত যে, কিছু ক্ষেত্রে, প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রগুলি বিভিন্ন বিভাগে শ্রেণীবদ্ধ করা হয় এবং এই ক্ষেত্রগুলি প্লাস্টিকের ব্যবহার নিয়ন্ত্রণ করে। উদাহরণস্বরূপ: কর্নিং এই জাতীয় একটি পণ্যের উপযোগিতা নিয়ন্ত্রণ করে কারণ এটি প্লাস্টিকের উপাদান ব্যবহার করে এবং প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রগুলির অধিকারী। অতএব, এই জাতীয় পণ্যগুলি কর্নিং বিভাগে শ্রেণীবদ্ধ করা হবে। শীঘ্রই: অন্যান্য প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্র প্রযুক্তিগত নকল বা অনুকরণের জন্য বিভিন্ন প্রক্রিয়াকরণ এবং প্রযুক্তির ব্যবহার নিয়ন্ত্রণ করে এবং সাধারণত প্লাস্টিকের উপযোগিতা ব্যবহার করে তৈরি করা হয়। এই জাতীয় পণ্যগুলি প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রের বিভাগে শ্রেণীবদ্ধ করা হবে। এটি লক্ষ করা উচিত যে, কিছু ক্ষেত্রে, প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রগুলি বিভিন্ন বিভাগে শ্রেণীবদ্ধ করা হয় এবং এই ক্ষেত্রগুলি প্লাস্টিকের ব্যবহার নিয়ন্ত্রণ করে। উদাহরণস্বরূপ: কর্নিং এই জাতীয় একটি পণ্যের উপযোগিতা নিয়ন্ত্রণ করে কারণ এটি প্লাস্টিকের উপাদান ব্যবহার করে এবং প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্রগুলির অধিকারী। অতএব, এই জাতীয় পণ্যগুলি কর্নিং বিভাগে শ্রেণীবদ্ধ করা হবে। শীঘ্রই: অন্যান্য প্লাস্টিকের মূর্তি এবং আলংকারিক জিনিসপত্র প্রযুক্তিগত নকল বা অনুকরণের জন্য বিভিন্ন প্রক্রিয়াকরণ এবং প্রযুক্তির ব্যবহার নিয়ন্ত্রণ করে এবং সাধারণত প্লাস্টিকের উপযোগিতা ব্যবহার করে তৈরি করা হয়। এই জাতীয় পণ্�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  কোনো যানবাহনে কি কি শ্রেণির অথবা বর্ণনার নৌযানের চলাচল নিষিদ্ধ?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nকোনো যানবাহনে কি কি শ্রেণির অথবা বর্ণনার নৌযানের চলাচল নিষিদ্ধ?\nassistant\nপ্রতিটি যানবাহনের নিট ভোল্যুম, উদ্ভিদ উত্পাদনের জন্য নির্ধারিত শ্রেণি এবং বর্ণনা নৌযানগুলি প্রয়োজন না কারণ, সকল প্রকার যানবাহনের জন্য সাধারণত একই শ্রেণি এবং বর্ণনা প্রয়োজন। তদুপরি, সরকার যে কোনও প্রকার যানবাহনকে ভিন্ন করতে পারে। তদুপরি, সরকার যে কোনও সময়ে নিষিদ্ধ কোনো যানবাহন ব্যবস্থা গ্রহণ করিতে পারে। অতএব, কোনো নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা যাকে সংশ্লিষ্ট ভাবে প্রভাবিত বলে মনে করা হয় একটি পরিষেবা। কারণ, এই দ্বারা উল্লিখিত যানবাহনগুলি সকল প্রকার যানবাহনের ক্ষেত্রে প্রযোজ্য শর্ত এবং বিধানগুলি প্রয়োগ করা হবে। উদাহরণস্বরূপ: সিএনজি জেনারেটরের ক্ষেত্রে, সহজেই দুটি শ্রেণি এবং একটি বর্ণনা রয়েছে, যথা:- ১। সিএনজি জেনারেটর (মোটর ইঞ্জিন শ্রেণীর যানবাহন); ২। সিএনজি জেনারেটর (চলঢঢাকারী যানবাহনের এন্ট্রি); কর্মসংস্থান স্থান থেকে সরবরাহ করা পর্যন্ত। এই দুটি শ্রেণিতে কোনো প্রকার নিষিদ্ধ কোনো সিএনজি জেনারেটর ছাড়া অন্য কোনো সিএনজি জেনারেটরের ক্ষেত্রে যথাযথ ব্যবস্থা গ্রহণ করা হবে। উদাহরণ 2: যদি সরকার সিএনজি জেনারেটরগুলির উপর শুল্ক আরোপ করে বা উক্ত প্রক্রিয়াকরণ শুরু হওয়ার সাথে সম্পর্কিত কোনো প্রক্রিয়াকরণ বা উপকরণ আমদানির সাথে সম্পর্কিত কোনো বিধান প্রবর্তন করে, তাহলে এই নতুন বিধানগুলি সকল সিএনজি জেনারেটরের ক্ষেত্রে প্রযোজ্য হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা হবে। এই ক্ষেত্রে, নিষিদ্ধ যানবাহনের শ্রেণি বা বর্ণনা প্রদান করা\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  ভ্যাট গ্রাহকের দায়িত্ব কী?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nভ্যাট গ্রাহকের দায়িত্ব কী?\nassistant\nএকজন ভ্যাট গ্রাহক নিম্নের দায়িত্বগুলি পালন করবে - বিধি 18 (খ) এর অধীনে ভ্যাট বিধান সম্পর্কিত তথ্য প্রদান করবে; বিধি 18 (গ) এর অধীনে গ্রাহক বিল ইনঅর্ডার প্রদান করবে; এবং বিধি 18 (গ) -এর অধীনে নিম্নলিখিত পদ্ধতিতে ভ্যাট বিধান পরিপালন করবে: গ্রাহক এই দুটি পদ্ধতিতে ভ্যাট বিধান পরিপালন করতে পারেন, যথা:- (ক) গ্রাহক মূল্য ঘোষণা সরবরাহ করেন; বিল অর্পণ করেন; এবং বিল দাখিল করেন; (খ) গ্রাহক ভ্যাট মূল্য ঘোষণা সরবরাহ করে, বিল অর্পণ করে এবং বিল দাখিল করে সরবরাহকারীকে বিল দ)_ 5 (পাঁচ) কেজি ভ্যাট দাখিল করে। এই দুটি পদ্ধতির মধ্যে যে কোনও পদ্ধতি ব্যবসায়িক নির্দিষ্টতা এবং স্বল্পমেয়াদের বিপরীতে কাজ করতে পারে। কখনও কখনও না কখনও ভ্যাট গ্রাহক মূল্য ঘোষণা সরবরাহ করেন, বিল অর্পণ করেন এবং বিল দাখিল করেন এমন ক্ষেত্রে ভ্যাট বিধান প্রযোজ্য হবে এবং কখনও কখনও না কখনও গ্রাহক বিল ইনঅর্ডার প্রদান মান এমন ক্ষেত্রে ভ্যাট বিধান প্রযোজ্য হবে না। এটি লক্ষ করা উচিত যে ভ্যাট বিধান সম্পর্কিত তথ্য এবং বিল অর্পণ এবং বিল দাখিল সম্পর্কিত প্রশ্নগুলি পুনরায় প্রশ্ন করা হয় কারণ এটি সমস্ত সমস্যা বা পরিস্থিতির জন্য একটি প্রতিষ্ঠাতা হতে পারে। উদাহরণস্বরূপ: একটি সংস্থা অগ্রি ফার্মাসিউটিক্যালস লিমিটেড এর ভ্যাট গ্রাহক উত্সটিতে ভ্যাট বিধান পরিপালন করতে কাজ করতে পারে। এই ক্ষেত্রে, ভ্যাট গ্রাহক মূল্য ঘোষণা সরবরাহ করেছে, বিল অর্পণ করেছে এবং বিল দাখিল করেছে। এই তথ্যটি একজন ভ্যাট গ্রাহক কর্তৃক প্রদান করা হয়েছে এবং সংস্থাটি এই তথ্যটিতে ভ্যাট প্রদান করতে পারেছে। অবশিষ্ট বিল দাখিলের ক্ষেত্রে, যদি গ্রাহক বিল ইনঅর্ডার প্রদানের তারিখে বিল দাখিলের তারিখ ব্যতীত অন্য কোনও তারিখে দাখিল করা হয় তবে বিধি 18 (গ) এর উপ-বিধি (3) অনুসারে গ্রাহক কর্তৃপক্ষ কর্তৃক দাখিলকৃত বিল দাখিলের ক্ষেত্রে ভ্যাট প্রদান করা হবে না। এই তথ্যটি একজন ভ্যাট গ্রাহক কর্তৃক প্রদান করা হয়েছে এবং সংস্থাটি এই তথ্যটিতে ভ্যাট প্রদান করতে পারেছে। এইভাবে, একজন ভ্যাট গ্রাহকের দায়িত্ব হ'ল ভ্যাট বিধান সম্পর্�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  কমিশনার কীভাবে বিকল্প বিরোধ নিষ্পত্তিতে মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়ককে মনোনীত করেন?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nকমিশনার কীভাবে বিকল্প বিরোধ নিষ্পত্তিতে মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়ককে মনোনীত করেন?\nassistant\nমূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়ককে মনোনীত করার জন্য, কমিশনার বিকল্প বিরোধ নিষ্পত্তির ক্ষেত্রে স্থানীয় বা আদালতের ন্যায্য প্রতিক্রিয়া প্রদানের মাধ্যমে মূল্য সংযোজন কর বিভাগকে প্রতিনিধিত্ব করবেন। এটি কমিশনারের নিকট প্রতিষ্ঠিত বিশ্বাসকে তুলে ধারণ করে, যে তার পক্ষে রাষ্ট্রের আইনের অধীনে কাজ করে এবং কার্যকর পদ্ধতিতে বিকল্প বিরোধ নিষ্পত্তি প্রদান করে। মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়ক নিয়োগের জন্য, কমিশনার বিভাগীয় সহায়কের ন্যায্য প্রতিক্রিয়া প্রদানের মাধ্যমে মূল্য সংযোজন কর বিভাগকে প্রতিনিধিত্ব করবেন। এটি কমিশনারের নিকট প্রতিষ্ঠিত বিশ্বাসকে তুলে ধারণ করে, যে তার পক্ষে রাষ্ট্রের আইনের অধীনে কাজ করে এবং কার্যকর পদ্ধতিতে বিকল্প বিরোধ নিষ্পত্তি প্রদান করে। তদুপরি, কমিশনার বিভাগীয় সহায়কের কর্তৃক প্রাপ্ত সমস্ত রাষ্ট্রীয় আইন ও বিধির প্রতি সমর্থন ও প্রতিপালন নিশ্চিত করবেন। এইরূপ, মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়কের নিয়োগ করার জন্য কমিশনারের যুক্তিসঙ্গত কারণ থাকবে। এটি লটেরি বা অনুরূপ পদ্ধতিতে ভাতা বা অন্যান্য ব্যয়কে কতিপয়ভাবে সমর্থন করার জন্য বিভাগীয় সহায়কের দয়ত্বে রাজস্ব কর্তৃপক্ষের কর্তৃত্বকেও অন্তর্ভুক্ত করতে পারে। শেষ অধিকারী এই জাতীয় কোন বিধানকে মেনে চলতে অসম্মত হলে, তাহা হইলে কমিশনার যে কোন মাধ্যমে বিকল্প বিরোধ নিষ্পত্তির আদেশ প্রদান করিতে পারিবেন, যেমন আবেদনপত্র প্রাপ্তির তারিখ হইতে কমপক্ষে তিন মাসকালীন সময় রক্ষণাবেক্ষণ করা, শুল্ক আরোপযোগ্য পণ্যের উপর অবিলম্বে আংশিক বা সম্পূর্ণ শুল্ক আরোপ করা, ইত্যাদি আদেশ প্রদান করিতে পারিবেন। এইরূপ, মূল্য সংযোজন কর বিভাগের জন্য বিভাগীয় সহায়কের নিয়োগ করার ক্ষেত্রে কমিশনারের যুক্তিসঙ্গত কারণ থাকবে। এটি লটেরি বা অনুরূপ পদ্ধতিতে ভাতা বা অন্যান্য ব্যয়কে কতিপয়ভাবে সমর্থন করার জন্য বিভাগীয় সহায়কের দয়ত্বে রাজস্ব কর্তৃপক্ষের কর্তৃত্বকেও অন্তর্ভুক্ত করতে পারে। শে�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  অতিরিক্ত কমিশনার অফ ট্যাক্সেস (আপীল)\" শব্দটি কাকে বোঝায় এবং আইনে এটি কোথায় উল্লেখ করা হয়েছে?\n"},{"name":"stdout","text":"Answer: system\nPlease provide a detailed answer\nuser\nঅতিরিক্ত কমিশনার অফ ট্যাক্সেস (আপীল)\" শব্দটি কাকে বোঝায় এবং আইনে এটি কোথায় উল্লেখ করা হয়েছে?\nassistant\n\"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এবং বোর্ডের সদস্য সম্পর্কিত অন্য কোনও ব্যক্তিকে অভিহিত করতে পারেন। আপীল ট্রাইব্যুনালের সদস্যদের একত্রিত ব্যক্তি। আইনে উল্লেখ করা হয়নি। এটি উল্লেখ করা হয়নি। এটি উল্লেখ করা হয়নি। এই তথ্যটি আইনে উল্লেখ করা হয়েছে। সংশ্লিষ্ট আইনের বিধানগুলি অনুসারে, \"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এবং বোর্ডের সদস্য সম্পর্কিত অন্য কোনও ব্যক্তিকে অভিহিত করতে পারেন। আপীল ট্রাইব্যুনালের সদস্যদের একত্রিত ব্যক্তি। আইনে উল্লেখ করা হয়নি। এই তথ্যটি আইনে উল্লেখ করা হয়েছে। সংশ্লিষ্ট আইনের বিধানগুলি অনুসারে, \"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এবং বোর্ডের সদস্য সম্পর্কিত অন্য কোনও ব্যক্তিকে অভিহিত করতে পারেন। আপীল ট্রাইব্যুনালের সদস্যদের একত্রিত ব্যক্তি। আইনে উল্লেখ করা হয়নি। এই তথ্যটি আইনে উল্লেখ করা হয়েছে। সংশ্লিষ্ট আইনের বিধানগুলি অনুসারে, \"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এবং বোর্ডের সদস্য সম্পর্কিত অন্য কোনও ব্যক্তিকে অভিহিত করতে পারেন। আপীল ট্রাইব্যুনালের সদস্যদের একত্রিত ব্যক্তি। আইনে উল্লেখ করা হয়নি। এই তথ্যটি আইনে উল্লেখ করা হয়েছে। সংশ্লিষ্ট আইনের বিধানগুলি অনুসারে, \"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এবং বোর্ডের সদস্য সম্পর্কিত অন্য কোনও ব্যক্তিকে অভিহিত করতে পারেন। আপীল ট্রাইব্যুনালের সদস্যদের একত্রিত ব্যক্তি। আইনে উল্লেখ করা হয়নি। এটি উল্লেখ করা হয়নি। এটি উল্লেখ করা হয়নি। এই তথ্যটি আইনে উল্লেখ করা হয়েছে। সংশ্লিষ্ট আইনের বিধানগুলি অনুসারে, \"অতিরিক্ত কমিশনার (আপীল)\" বলতে কমিশনার অব ট্যাক্সেস (আপীল), কমিশনার অব ট্যাক্সেস (মুসাক -12), এব�\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or type 'quit' to exit):  quit\n"},{"name":"stdout","text":"Exiting the Q&A session.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Save the fine-tuned model\n# trainer.model.save_pretrained(new_model)\n# trainer.model.create_model_card()\n# trainer.model.push_to_hub(new_model, use_temp_dir=False)\n\n# Save the base model with adapters merged\nmodel = model.merge_and_unload()  # Merge the LoRA adapters back into the model\nmodel.save_pretrained(new_model)  # Save the full model to `new_model`\ntokenizer.save_pretrained(new_model)  # Save tokeniqqqqqbzer as well","metadata":{"_uuid":"0e5e5cc3-ee15-4740-a012-6f7f495b829e","_cell_guid":"8e9cfa4a-fb53-401e-a63b-5e18658821f7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T19:14:46.708015Z","iopub.execute_input":"2024-11-10T19:14:46.708772Z","iopub.status.idle":"2024-11-10T19:14:46.734150Z","shell.execute_reply.started":"2024-11-10T19:14:46.708727Z","shell.execute_reply":"2024-11-10T19:14:46.732862Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# trainer.model.save_pretrained(new_model)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# trainer.model.create_model_card()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# trainer.model.push_to_hub(new_model, use_temp_dir=False)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save the base model with adapters merged\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mmerge_and_unload()  \u001b[38;5;66;03m# Merge the LoRA adapters back into the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)  \u001b[38;5;66;03m# Save the full model to `new_model`\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)  \u001b[38;5;66;03m# Save tokeniqqqqqbzer as well\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T14:32:26.306464Z","iopub.status.idle":"2024-11-10T14:32:26.306829Z","shell.execute_reply.started":"2024-11-10T14:32:26.306655Z","shell.execute_reply":"2024-11-10T14:32:26.306673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from huggingface_hub import HfApi\n\n# api = HfApi()\n\n# # Push full model to Hugging Face\n# api.upload_folder(\n#     folder_path=new_model, \n#     repo_id=\"Zafor158/odiaGenAI-finance-bengali-finetuned-model-v1\", \n#     use_auth_token=write_token\n# )","metadata":{"_uuid":"eb4bd268-b1a3-4820-a408-d4982c510449","_cell_guid":"55d8bd71-82fd-43a1-a308-9c4cf0c4a976","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-10T14:32:26.307727Z","iopub.status.idle":"2024-11-10T14:32:26.308047Z","shell.execute_reply.started":"2024-11-10T14:32:26.307883Z","shell.execute_reply":"2024-11-10T14:32:26.307900Z"},"trusted":true},"outputs":[],"execution_count":null}]}